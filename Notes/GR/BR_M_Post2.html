<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
    <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
    <title>1</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>

    <link rel="stylesheet" href="../../te.css">
    <script src="../../marked.min.js"></script>
    <script src ='../../script.js'></script>
    <!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
    <script type="text/x-mathjax-config">
        init_mathjax = function() {
            if (window.MathJax) {
            // MathJax loaded
                MathJax.Hub.Config({
                    TeX: {
                        equationNumbers: {
                        autoNumber: "AMS",
                        useLabelIds: true
                        }
                    },
                    tex2jax: {
                        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                        processEscapes: true,
                        processEnvironments: true
                    },
                    displayAlign: 'center',
                    messageStyle: 'none',
                    CommonHTML: {
                        linebreaks: {
                        automatic: true
                        }
                    }
                });

                MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
            }
        }
        init_mathjax();
    </script>
    <!-- End of mathjax configuration -->
<body class="notes">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=6572b6d9-d87c-4316-afbf-89879bba03dd">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Tensor-Operations">Tensor Operations<a class="anchor-link" href="#Tensor-Operations"></a></h2><p>Now, it's possible to define common tensor operations. The most common one is (self) contraction. Given a tensor with one upper and one lower index each at minimum $T^u_v$, a (self) contraction is essentially a self sum. Quantitatively, $T^v_u dx^u \partial_v = T( \ , \  ) \rightarrow T^v_udx^u(\partial_\alpha)\partial_v(dx^\alpha) = T^v_u\delta^u_\alpha \delta_v^\alpha = T^u_u$. It is definitionally a little confusing, but essentially each basis element is being multiplied out in a sense.</p>
<p>Contraction for general tensors is defined through the use of the metric tensor. Recall that each vector $v$ is associated with a dual vector $v^*$ through the metric. The operation of changing a vector index to a dual index or vice versa is called lowering, or raising the index, respectively. This applies to tensors since they are just multilinear products of vectors and their duals. For an example, consider the tensor $A = A_{uv\lambda}^{\alpha \beta} dx^u dx^v dx^\lambda \partial_\alpha \partial_\beta$. This is of rank $(3,2)$. Lowering the $\alpha$ index, $g_{\sigma \alpha}A_{uv \lambda}^{\alpha \beta} = A_{\sigma uv\lambda}^\beta$. Therefore, contraction reduces the rank of a tensor from $(m,n)$ to $(m-1,n-1)$.</p>
<p>Symmetrization and anti-symmetrization are other important operations. Given a tensor $A_{uv}$, the symmetric part of $A_{uv}$ is defined as $A_{(uv)} = \frac{1}{2} ( A_{uv} + A_{vu})$, and the anti-symmetric part is defined as $A_{[uv]} = \frac{1}{2} ( A_{uv} - A_{vu})$. Note that $A_{(uv)} + A_{[uv]} = A_{uv}$. In general, all possible permutations are added for the symmetric part, while odd permuations are subracted and even permutations are added for the anti-symmetric part. In both cases, the average over the number of possible terms is taken. For example, $T_{uv\alpha}, T_{(uv\alpha)} = \frac{1}{6} (T_{uv\alpha} + T_{v u \alpha} + T_{\alpha u v}  + T_{u\alpha v} +  T_{v\alpha u} + T_{\alpha v u})$
$T_{[uv\alpha]} = \frac{1}{6} (T_{uv\alpha} - T_{v u \alpha} + T_{\alpha u v}  - T_{u\alpha v} +  T_{v\alpha u} - T_{\alpha v u})$.</p>
<h2 id="Differential-Forms">Differential Forms<a class="anchor-link" href="#Differential-Forms"></a></h2><p>Now, consider only the set of dual vectors. There are operations which are defined only on this set. The biggest one is the wedge product of two dual vectors, defined as $w^u \wedge w^v = w^u \otimes w^v - w^v \otimes w^u = w^u w^v - w^v w^u$. The wedge product leads nicely to the concept of forms and exterior derivatives. The fundamental concept in this context, which is that of a one form. This is directly equivalent to the concept of a dual vector and is represented as $dx^\alpha$ in the $\{\alpha\}$ basis. The space of one-forms is the space of dual vectors. Therefore, taking the wedge product of two one-forms $dx^\alpha \wedge dx^\beta$ produces a two-form. A three-form is defined with two wedge products of one forms $dx^\alpha \wedge dx^\beta \wedge dx^\gamma $, and similarly any p-form can be defined, with p being any positive integer.</p>
<p>Consider the dimensionality of these forms. $Dim(V^*) = Dim(\lambda^1)$, where $\lambda^1$ is the space of all one-forms. What is $Dim(\lambda^2)$, the space of all two-forms? If there are n basis vectors in the dual space, there are $\frac{n(n-1)}{2}$ anti-symmetric combinations possible for the creation of a two-form. Any symmetric combinations cannot exist since $dx^\alpha \wedge dx^\alpha = 0$ For example, if $n = 4$ as it is in GR, there are 6 independent 2-forms. 6 other ones exist, but they are merely the negative of these, since $dx^u \wedge dx^v = - dx^v \wedge dx^u $. Now, considering 3-forms, it is easy to see that there are 4 unique elements in this. There is only 1 unique 4-form. And there are no higher dimensional forms since that will only be possible if a basis one-form element repeats itself in the basis definition of these higher dimensional forms, which would result in the form evaluating to zero. In general, there are $\binom{n}{p}$ unique p-forms formed from a vector space of dimension n.</p>
<p>For example, in Lorentzian spacetime, $\{dx^\alpha\} = {dx^0,dx^i}$. The basis two forms are $dx^0 \wedge dx^1, dx^0 \wedge dx^2,dx^0 \wedge dx^3, dx^1 \wedge dx^2,dx^1 \wedge dx^3,dx^2 \wedge dx^3.$ The basis 3-forms are $dx^0 \wedge dx^1 \wedge dx^2,dx^0 \wedge dx^1 \wedge dx^3, dx^1 \wedge dx^2 \wedge dx^3, dx^0 \wedge dx^2 \wedge dx^3  $. The basis 4-form is $ dx^0 \wedge dx^1 \wedge dx^2 \wedge dx^3 $. There is no basis 5-form or higher since $dx^\alpha \wedge dx^0 \wedge dx^1 \wedge dx^2 \wedge dx^3 = 0  , \forall \alpha $.</p>
<h2 id="Exterior-Derivative">Exterior Derivative<a class="anchor-link" href="#Exterior-Derivative"></a></h2><p>This leads to the concept of the exterior derivative. It is the generalization of the gradient of a scalar to p-forms and represented as $d$. Consider a p-form $\sigma = \sigma_{uv}dx^u \wedge dx^v$ (Note the factor of $\frac{1}{2}$ has just been absorbed into the coefficients as is common to do). The exterior derivative acts such that $d\sigma = \partial_\alpha \sigma_{uv} dx^\alpha \wedge dx^u \wedge dx^v $. It takes a p-form to a (p+1)-form. If it acts on a scalar, which is trivially defined as a 0-form, meaning a tensor of rank $(0,0)$, $df= \partial_\alpha f dx^\alpha $. Note the $\partial_\alpha f$ are just the components of the gradient of a scalar function as defined in vector calculus. Note that while it is represented as a vector usually, it is in fact a dual vector (though dual vectors are also vectors and the metric in Euclidean space ensures a 1-1 correspondence, so this point is not relevant in that setting, though still more accurate).</p>
<p>Consider the operation $d^2$. Acting on a tensor p-form $\sigma = \sigma_{uv}dx^u \wedge dx^v$ , $d^2 (\sigma) = d (\partial_\alpha \sigma_{uv} dx^\alpha \wedge dx^ u \wedge dx^v) = \partial_\beta (\partial_\alpha \sigma_{uv}) dx^\beta \wedge  dx^\alpha \wedge dx^ u \wedge dx^v$ . The equality of partial derivatives ensures $d^2 \sigma = \partial_\alpha(\partial_\beta \sigma_{uv}) dx^\beta \wedge  dx^\alpha \wedge dx^ u \wedge dx^v$. However, now the $\alpha, \beta$ indices can be relabeled, or interchanged with each other. $d^2 \sigma = \partial_\beta(\partial_\alpha \sigma_{uv}) dx^\alpha \wedge  dx^\beta \wedge dx^ u \wedge dx^v$. Then, since $dx^\alpha \wedge dx^\beta = -dx^\beta \wedge dx^\alpha $ This ensures that $\partial_\alpha(\partial_\beta \sigma_{uv}) dx^\beta \wedge  dx^\alpha \wedge dx^ u \wedge dx^v = -\partial_\alpha(\partial_\beta \sigma_{uv}) dx^\beta \wedge  dx^\alpha \wedge dx^ u \wedge dx^v \Rightarrow d^2 \sigma = 0$ by the linear independence of the basis elements. Note that this is independent of the form of $\sigma$. It could be any p-form, and the result would be the same. Therefore, $d^2 = 0$ in general.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=392c879c-ef29-4042-afa7-c80bdaa99309">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
</div>
</div>
</div>
</div>
</main>
</body>
</html>
